{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting sentiment from product reviews\n",
    "\n",
    "\n",
    "The goal of this first notebook is to explore logistic regression and feature engineering with existing GraphLab functions.\n",
    "\n",
    "In this notebook you will use product review data from Amazon.com to predict whether the sentiments about a product (from its reviews) are positive or negative.\n",
    "\n",
    "* Do some feature engineering\n",
    "* Train a logistic regression model to predict the sentiment of product reviews.\n",
    "* Inspect the weights (coefficients) of a trained logistic regression model.\n",
    "* Make a prediction (both class and probability) of sentiment for a new product review.\n",
    "* Given the logistic regression weights, predictors and ground truth labels, write a function to compute the **accuracy** of the model.\n",
    "* Inspect the coefficients of the logistic regression model and interpret their meanings.\n",
    "* Compare multiple logistic regression models.\n",
    "\n",
    "Let's get started!\n",
    "    \n",
    "## Load libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have the latest version of GraphLab Create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "#import graphlab\n",
    "import math\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#import sframe\n",
    "#products = sframe.SFrame('amazon_baby.gl/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation \n",
    "\n",
    "## 1. Load Amazon dataset\n",
    "\n",
    "We will use a dataset consisting of baby product reviews on Amazon.com.\n",
    "* Load the dataset consisting of baby product reviews on Amazon.com. \n",
    "* Store the data in a data frame products. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv('amazon_baby.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us see a preview of what the dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the word count vector for each review\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explore a specific example of a baby product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name      The First Years Massaging Action Teether\n",
       "review                    A favorite in our house!\n",
       "rating                                           5\n",
       "Name: 269, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.loc[269]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perform text cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will perform 2 simple data transformations:\n",
    "\n",
    "1. Remove punctuation using [Python's built-in](https://docs.python.org/2/library/string.html) string functionality.\n",
    "2. Transform the reviews into word-counts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn instruction\n",
    "* We start by removing punctuation, so that words \"cake.\" and \"cake!\" are counted as the same word.\n",
    "\n",
    "Write a function remove_punctuation that strips punctuation from a line of text\n",
    "Apply this function to every element in the review column of products, and save the result to a new column review_clean\n",
    "```python\n",
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return text.translate(None, string.punctuation) \n",
    "\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)\n",
    "```\n",
    "\n",
    "**Aside**. In this notebook, we remove all punctuations for the sake of simplicity. A smarter approach to punctuations would preserve phrases such as \"I'd\", \"would've\", \"hadn't\" and so forth. See [this page](https://www.cis.upenn.edu/~treebank/tokenization.html) for an example of smart handling of punctuations.\n",
    "\n",
    "\n",
    "**IMPORTANT**. Make sure to fill n/a values in the **review** column with empty strings (if applicable). The n/a values indicate empty reviews. For instance, Pandas's the fillna() method lets you replace all N/A's in the **review** columns as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products.fillna({'review':''})  # fill in N/A's in the review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    try:\n",
    "        return text.translate(None, string.punctuation) \n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "products['review_clean']  = products['review'].apply(remove_punctuation)\n",
    "\n",
    "#products['word_count'] = graphlab.text_analytics.count_words(review_without_punctuation)\n",
    "#Convert the content of string/dict/list type SArrays to a dictionary of (word, count) pairs. \n",
    "#The strings are first tokenized into words according to the specified to_lower and delimiters options. Then, word counts are accumulated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products.fillna({'review_clean':''})  # fill in N/A's in the review column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract sentiments\n",
    "\n",
    "We will **ignore** all reviews with *rating = 3*, since they tend to have a neutral sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183531\n"
     ]
    }
   ],
   "source": [
    "print(len(products))\n",
    "products = products[products['rating'] != 3]\n",
    "len(products)\n",
    "products = products.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will assign reviews with a rating of 4 or higher to be *positive* reviews, while the ones with rating of 2 or lower are *negative*. For the sentiment column, we use +1 for the positive class label and -1 for the negative class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82623</th>\n",
       "      <td>90959</td>\n",
       "      <td>MAM Bite and Brush Teether, 3 Months, Colors M...</td>\n",
       "      <td>My search criteria on Amazon.com was \"made in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>My search criteria on Amazoncom was made in th...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45782</th>\n",
       "      <td>50350</td>\n",
       "      <td>Baby Einstein Discover &amp;amp; Play Color Block</td>\n",
       "      <td>My 4 month old likes to grip objects, and ther...</td>\n",
       "      <td>2</td>\n",
       "      <td>My 4 month old likes to grip objects and there...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133779</th>\n",
       "      <td>147173</td>\n",
       "      <td>BRICA Corner Bath Basket Toy Organizer</td>\n",
       "      <td>This sticks great to the sides of our bathtub....</td>\n",
       "      <td>5</td>\n",
       "      <td>This sticks great to the sides of our bathtub ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61629</th>\n",
       "      <td>67837</td>\n",
       "      <td>Fisher-Price 2-in-1 Projection Mobile, Preciou...</td>\n",
       "      <td>This thing is awesome! I only wish i had gotte...</td>\n",
       "      <td>5</td>\n",
       "      <td>This thing is awesome I only wish i had gotten...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25413</th>\n",
       "      <td>27840</td>\n",
       "      <td>Pigeon Baby Nose Cleaning Tweezers Pigeon (Mad...</td>\n",
       "      <td>Honestly, this product is not worth the $7.45 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Honestly this product is not worth the 745 I s...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                               name  \\\n",
       "82623    90959  MAM Bite and Brush Teether, 3 Months, Colors M...   \n",
       "45782    50350      Baby Einstein Discover &amp; Play Color Block   \n",
       "133779  147173             BRICA Corner Bath Basket Toy Organizer   \n",
       "61629    67837  Fisher-Price 2-in-1 Projection Mobile, Preciou...   \n",
       "25413    27840  Pigeon Baby Nose Cleaning Tweezers Pigeon (Mad...   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "82623   My search criteria on Amazon.com was \"made in ...       1   \n",
       "45782   My 4 month old likes to grip objects, and ther...       2   \n",
       "133779  This sticks great to the sides of our bathtub....       5   \n",
       "61629   This thing is awesome! I only wish i had gotte...       5   \n",
       "25413   Honestly, this product is not worth the $7.45 ...       1   \n",
       "\n",
       "                                             review_clean  sentiment  \n",
       "82623   My search criteria on Amazoncom was made in th...         -1  \n",
       "45782   My 4 month old likes to grip objects and there...         -1  \n",
       "133779  This sticks great to the sides of our bathtub ...          1  \n",
       "61629   This thing is awesome I only wish i had gotten...          1  \n",
       "25413   Honestly this product is not worth the 745 I s...         -1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
    "products.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see that the dataset contains an extra column called **sentiment** which is either positive (+1) or negative (-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split data into training and test sets\n",
    "Let's perform a train/test split with 80% of the data in the training set and 20% of the data in the test set. We use `seed=1` so that everyone gets the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((166752, 6), (133416, 5), (33336, 5))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data, test_data = products.random_split(.8, seed=1)\n",
    "#print len(train_data)\n",
    "#print len(test_data)\n",
    "train_indices = pd.read_json('module-2-assignment-train-idx.json')[0]\n",
    "test_indices  = pd.read_json('module-2-assignment-test-idx.json')[0]\n",
    "\n",
    "train_data = products.loc[train_indices]\n",
    "test_data = products.loc[test_indices]\n",
    "\n",
    "train_data = train_data.reset_index()\n",
    "test_data =  test_data.reset_index()\n",
    "train_data = train_data.drop(['index','level_0'], axis= 1  )\n",
    "test_data  = test_data.drop (['index','level_0'], axis= 1  )\n",
    "\n",
    "y_train = train_data['sentiment']\n",
    "y_test  = test_data['sentiment']\n",
    "\n",
    "\n",
    "#train_data.head()\n",
    "#test_data.head()\n",
    "products.shape, train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>This has been an easy way for my nanny to reco...</td>\n",
       "      <td>4</td>\n",
       "      <td>This has been an easy way for my nanny to reco...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>I love this journal and our nanny uses it ever...</td>\n",
       "      <td>4</td>\n",
       "      <td>I love this journal and our nanny uses it ever...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies First Year Sticker Calendar</td>\n",
       "      <td>I love this little calender, you can keep trac...</td>\n",
       "      <td>5</td>\n",
       "      <td>I love this little calender you can keep track...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>I had a hard time finding a second year calend...</td>\n",
       "      <td>5</td>\n",
       "      <td>I had a hard time finding a second year calend...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>One of babys first and favorite books and it i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "1  Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "2     Nature's Lullabies First Year Sticker Calendar   \n",
       "3    Nature's Lullabies Second Year Sticker Calendar   \n",
       "4                        Lamaze Peekaboo, I Love You   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  This has been an easy way for my nanny to reco...       4   \n",
       "1  I love this journal and our nanny uses it ever...       4   \n",
       "2  I love this little calender, you can keep trac...       5   \n",
       "3  I had a hard time finding a second year calend...       5   \n",
       "4  One of baby's first and favorite books, and it...       4   \n",
       "\n",
       "                                        review_clean  sentiment  \n",
       "0  This has been an easy way for my nanny to reco...          1  \n",
       "1  I love this journal and our nanny uses it ever...          1  \n",
       "2  I love this little calender you can keep track...          1  \n",
       "3  I had a hard time finding a second year calend...          1  \n",
       "4  One of babys first and favorite books and it i...          1  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build the word count vector for each review\n",
    "Now, let us explore what the sample example above looks like after these 2 transformations. Here, each entry in the **word_count** column is a dictionary where the key is the word and the value is a count of the number of times the word occurs.\n",
    "\n",
    "```python\n",
    "def count_words(string):\n",
    "    string= string.lower().split(' ')\n",
    "    dt ={}\n",
    "    for word in string:\n",
    "        if len(word)>0:\n",
    "            dt[word] = dt.get(word,0) + 1\n",
    "    return dt\n",
    "\n",
    "#count_words( product['review'][1]) \n",
    "\n",
    "products['word_count'] = products['review_clean'].apply(count_words)\n",
    "print (products.loc[269]['word_count'])\n",
    "products.head()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now compute the word count for each word that appears in the reviews. \n",
    "\n",
    "* A vector consisting of word counts is often referred to as **bag-of-word features**. \n",
    "Since most words occur in only a few reviews, word count vectors are sparse. \n",
    "For this reason, scikit-learn and many other tools use **sparse matrices** to store a collection of word count vectors. \n",
    "Refer to appropriate manuals to produce sparse word count vectors. \n",
    "\n",
    "* General steps for extracting word count vectors are as follows:\n",
    "  1. Learn a vocabulary (set of all words) from the training data. Only the words that show up in the training data will be considered for feature extraction.\n",
    "  * Compute the occurrences of the words in each review and collect them into a row vector.\n",
    "  * Build a sparse matrix where each row is the word count vector for the corresponding review. Call this matrix train_matrix.\n",
    "  * Using the same mapping between words and columns, convert the test data into a sparse matrix test_matrix.\n",
    "\n",
    "The following cell uses CountVectorizer in scikit-learn. Notice the token_pattern argument in the constructor.\n",
    "* Keep in mind that the test data must be transformed in the same way as the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')  \n",
    "# \\w: equal to [a-zA-Z0-9_]\n",
    "# + : >=1 repetitions\n",
    "# \\b: Matches the empty string, but only at the beginning or end of a word\n",
    "# Use this token pattern to keep single-letter words\n",
    "\n",
    "# First, learn vocabulary from the training data and assign columns to words\n",
    "# Then convert the training data into a sparse matrix\n",
    "train_matrix = vectorizer.fit_transform( train_data['review_clean'])\n",
    "\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectorizer.transform( test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>This has been an easy way for my nanny to reco...</td>\n",
       "      <td>4</td>\n",
       "      <td>This has been an easy way for my nanny to reco...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>I love this journal and our nanny uses it ever...</td>\n",
       "      <td>4</td>\n",
       "      <td>I love this journal and our nanny uses it ever...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies First Year Sticker Calendar</td>\n",
       "      <td>I love this little calender, you can keep trac...</td>\n",
       "      <td>5</td>\n",
       "      <td>I love this little calender you can keep track...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>I had a hard time finding a second year calend...</td>\n",
       "      <td>5</td>\n",
       "      <td>I had a hard time finding a second year calend...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>One of babys first and favorite books and it i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "1  Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "2     Nature's Lullabies First Year Sticker Calendar   \n",
       "3    Nature's Lullabies Second Year Sticker Calendar   \n",
       "4                        Lamaze Peekaboo, I Love You   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  This has been an easy way for my nanny to reco...       4   \n",
       "1  I love this journal and our nanny uses it ever...       4   \n",
       "2  I love this little calender, you can keep trac...       5   \n",
       "3  I had a hard time finding a second year calend...       5   \n",
       "4  One of baby's first and favorite books, and it...       4   \n",
       "\n",
       "                                        review_clean  sentiment  \n",
       "0  This has been an easy way for my nanny to reco...          1  \n",
       "1  I love this journal and our nanny uses it ever...          1  \n",
       "2  I love this little calender you can keep track...          1  \n",
       "3  I had a hard time finding a second year calend...          1  \n",
       "4  One of babys first and favorite books and it i...          1  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a sentiment classifier with logistic regression\n",
    "\n",
    "We will now use logistic regression to create a sentiment classifier on the training data. \n",
    "\n",
    "## 7. Learn a logistic regression classifier using the training data. \n",
    "* If you are using scikit-learn, you should create an instance of the LogisticRegression class and then call the method fit() to train the classifier. \n",
    "* This model should use the sparse word count matrix (train_matrix) as features and the column sentiment of train_data as the target. \n",
    "* Use the default values for other parameters. Call this model sentiment_model.\n",
    "\n",
    "* There should be over 100,000 coefficients in this sentiment_model. \n",
    "  * Recall from the lecture that positive weights w_j correspond to weights that cause positive sentiment, while negative weights correspond to negative sentiment. \n",
    "  * Calculate the number of positive (>= 0, which is actually nonnegative) coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "sentiment_model = clf.fit(X = train_matrix, y = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aside**. You may get a warning to the effect of \"Terminated due to numerical difficulties --- this model may not be ideal\". It means that the quality metric (to be covered in Module 3) failed to improve in the last iteration of the run. The difficulty arises as the sentiment model puts too much weight on extremely rare words. A way to rectify this is to apply regularization, to be covered in Module 4. Regularization lessens the effect of extremely rare words. For the purpose of this assignment, however, please proceed with the model above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fitted the model, we can extract the weights (coefficients) as an SFrame as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.24018043e+00,   2.90676284e-05,   2.75328664e-02, ...,\n",
       "          1.26018688e-02,   2.70953145e-03,  -4.15519037e-05]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = sentiment_model.coef_\n",
    "weights\n",
    "#weights.column_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of `121713` coefficients in the model. Recall from the lecture that positive weights $w_j$ correspond to weights that cause positive sentiment, while negative weights correspond to negative sentiment. \n",
    "\n",
    "Fill in the following block of code to calculate how many *weights* are positive ( >= 0). (**Hint**: The `'value'` column in SFrame *weights* must be positive ( >= 0))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive weights: 86908 \n",
      "Number of negative weights: 34804 \n"
     ]
    }
   ],
   "source": [
    "num_positive_weights = ( weights> 0).sum()\n",
    "num_negative_weights = ( weights< 0).sum()\n",
    "\n",
    "print \"Number of positive weights: %s \" % num_positive_weights\n",
    "print \"Number of negative weights: %s \" % num_negative_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** How many weights are >= 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86908"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( weights>= 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Making predictions with logistic regression\n",
    "\n",
    "Now that a model is trained, we can make predictions on the **test data**. In this section, we will explore this in the context of 3 examples in the test dataset.  We refer to this set of 3 examples as the **sample_test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10    5\n",
      "11    2\n",
      "12    1\n",
      "Name: rating, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>Absolutely love it and all of the Scripture in...</td>\n",
       "      <td>5</td>\n",
       "      <td>Absolutely love it and all of the Scripture in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wall Decor Removable Decal Sticker - Colorful ...</td>\n",
       "      <td>Would not purchase again or recommend. The dec...</td>\n",
       "      <td>2</td>\n",
       "      <td>Would not purchase again or recommend The deca...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>New Style Trailing Cherry Blossom Tree Decal R...</td>\n",
       "      <td>Was so excited to get this product for my baby...</td>\n",
       "      <td>1</td>\n",
       "      <td>Was so excited to get this product for my baby...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  \\\n",
       "10                          Our Baby Girl Memory Book   \n",
       "11  Wall Decor Removable Decal Sticker - Colorful ...   \n",
       "12  New Style Trailing Cherry Blossom Tree Decal R...   \n",
       "\n",
       "                                               review  rating  \\\n",
       "10  Absolutely love it and all of the Scripture in...       5   \n",
       "11  Would not purchase again or recommend. The dec...       2   \n",
       "12  Was so excited to get this product for my baby...       1   \n",
       "\n",
       "                                         review_clean  sentiment  \n",
       "10  Absolutely love it and all of the Scripture in...          1  \n",
       "11  Would not purchase again or recommend The deca...         -1  \n",
       "12  Was so excited to get this product for my baby...         -1  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data = test_data[10:13]\n",
    "print sample_test_data['rating']\n",
    "sample_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dig deeper into the first row of the **sample_test_data**. Here's the full review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Absolutely love it and all of the Scripture in it.  I purchased the Baby Boy version for my grandson when he was born and my daughter-in-law was thrilled to receive the same book again.'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data.loc[10,'review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That review seems pretty positive.\n",
    "\n",
    "Now, let's see what the next row of the **sample_test_data** looks like. As we could guess from the sentiment (-1), the review is quite negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Would not purchase again or recommend. The decals were thick almost plastic like and were coming off the wall as I was applying them! The would NOT stick! Literally stayed stuck for about 5 minutes then started peeling off.'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data.loc[11,'review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now make a **class** prediction for the **sample_test_data**. The `sentiment_model` should predict **+1** if the sentiment is positive and **-1** if the sentiment is negative. Recall from the lecture that the **score** (sometimes called **margin**) for the logistic regression model  is defined as:\n",
    "\n",
    "$$\n",
    "\\mbox{score}_i = \\mathbf{w}^T h(\\mathbf{x}_i)\n",
    "$$ \n",
    "\n",
    "where $h(\\mathbf{x}_i)$ represents the features for example $i$.  We will write some code to obtain the **scores**. For each row, the **score** (or margin) is a number in the range **[-inf, inf]**.\n",
    "\n",
    "Use a pre-built function in your tool to calculate the score of each data point in sample_test_data. In scikit-learn, you can call the decision_function() function.\n",
    "\n",
    "Hint: You'd probably need to convert sample_test_data into the sparse matrix format first.\n",
    "### 8.1 Use decision_function from LogisticRegression model to get scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.60155603  -3.17063642 -10.42378904]\n"
     ]
    }
   ],
   "source": [
    "# onvert sample_test_data into the sparse matrix format\n",
    "sample_test_matrix = vectorizer.transform(sample_test_data['review_clean'])\n",
    "\n",
    "scores = sentiment_model.decision_function(sample_test_matrix)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Predicting sentiment\n",
    "\n",
    "These scores can be used to make class predictions as follows:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & \\mathbf{w}^T h(\\mathbf{x}_i) > 0 \\\\\n",
    "      -1 & \\mathbf{w}^T h(\\mathbf{x}_i) \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Using scores, write code to calculate $\\hat{y}$, the class predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, -1, -1]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat =map(lambda x:  +1 if x >0 else -1, scores )\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to verify that the class predictions obtained by your calculations are the same as that obtained from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class predictions according to GraphLab Create:\n",
      "[ 1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "print \"Class predictions according to GraphLab Create:\" \n",
    "print sentiment_model.predict(sample_test_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**: Make sure your class predictions match with the one obtained from sklearn.\n",
    "\n",
    "### 8.3 Probability predictions\n",
    "\n",
    "Recall from the lectures that we can also calculate the probability predictions from the scores using:\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))}.\n",
    "$$\n",
    "\n",
    "Using the variable **scores** calculated previously, write code to calculate the probability that a sentiment is positive using the above formula. For each row, the probabilities should be a number in the range **[0, 1]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(scores):\n",
    "    return [1/(1+ np.exp(- score)) for score in scores ] \n",
    "prob = sigmoid(scores)\n",
    "\n",
    "\n",
    "assert prob == sentiment_model.predict_proba(sample_test_matrix)[:,1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**: Make sure your probability predictions match the ones obtained from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class predictions according to sklearn:\n",
      "[  9.96321467e-01   4.02858024e-02   2.97161836e-05]\n"
     ]
    }
   ],
   "source": [
    "print \"Class predictions according to sklearn:\" \n",
    "print  sentiment_model.predict_proba(sample_test_matrix)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quiz Question:** Of the three data points in **sample_test_data**, which one (first, second, or third) has the **lowest probability** of being classified as a positive review?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Find the most positive (and negative) review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now turn to examining the full test dataset, **test_matrix**, and use sklearn to form predictions on all of the test data points for faster performance.\n",
    "\n",
    "Using the `sentiment_model`, find the 20 reviews in the entire **test_data** with the **highest probability** of being classified as a **positive review**. We refer to these as the \"most positive reviews.\"\n",
    "\n",
    "To calculate these top-20 reviews, use the following steps:\n",
    "1.  Make probability predictions on **test_data** using the `sentiment_model`. (**Hint:** When you call `.predict` to make predictions on the test data, use option `output_type='probability'` to output the probability rather than just the most likely class.)\n",
    "2.  Sort the data according to those predictions and pick the top 20. (**Hint:** You can use the `.topk` method on an SFrame to find the top k rows sorted according to the value of a specified column.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_scores = sentiment_model.decision_function(test_matrix)\n",
    "test_prob = sentiment_model.predict_proba(test_matrix)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26838    Baby Jogger City Mini GT Double Stroller, Shad...\n",
       "30076    Ikea 36 Pcs Kalas Kids Plastic BPA Free Flatwa...\n",
       "33060    Summer Infant Wide View Digital Color Video Mo...\n",
       "26830    Baby Jogger City Mini GT Single Stroller, Shad...\n",
       "24899           Graco Pack 'n Play Element Playard - Flint\n",
       "15732      Baby Einstein Around The World Discovery Center\n",
       "9125            P'Kolino Silly Soft Seating in Tias, Green\n",
       "17558    Freemie Hands-Free Concealable Breast Pump Col...\n",
       "20743    Fisher-Price Cradle 'N Swing,  My Little Snuga...\n",
       "30634    Graco FastAction Fold Jogger Click Connect Str...\n",
       "11923         Evenflo 6 Pack Classic Glass Bottle, 4-Ounce\n",
       "4140        Britax Decathlon Convertible Car Seat, Tiffany\n",
       "30535    Buttons Cloth Diaper Cover - One Size - 8 Colo...\n",
       "18112    Infantino Wrap and Tie Baby Carrier, Black Blu...\n",
       "9555     Evenflo X Sport Plus Convenience Stroller - Ch...\n",
       "14482    Simple Wishes Hands-Free Breastpump Bra, Pink,...\n",
       "24286                    Britax 2012 B-Agile Stroller, Red\n",
       "32782        Mamas &amp; Papas 2014 Urbo2 Stroller - Black\n",
       "25554           Diono RadianRXT Convertible Car Seat, Plum\n",
       "21531    Roan Rocco Classic Pram Stroller 2-in-1 with B...\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 20 positive reviews \n",
    "test_data.loc[ np.argsort(test_prob)[-20:],'name' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which of the following products are represented in the 20 most positive reviews? [multiple choice]\n",
    "\n",
    "\n",
    "Now, let us repeat this exercise to find the \"most negative reviews.\" Use the prediction probabilities to find the  20 reviews in the **test_data** with the **lowest probability** of being classified as a **positive review**. Repeat the same steps above but make sure you **sort in the opposite order**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2931           Fisher-Price Ocean Wonders Aquarium Bouncer\n",
       "21700    Levana Safe N'See Digital Video Baby Monitor w...\n",
       "13939       Safety 1st Exchangeable Tip 3 in 1 Thermometer\n",
       "8818     Adiri BPA Free Natural Nurser Ultimate Bottle ...\n",
       "28184    VTech Communications Safe &amp; Sounds Full Co...\n",
       "17069    The First Years True Choice P400 Premium Digit...\n",
       "9655                   Safety 1st High-Def Digital Monitor\n",
       "14711                Cloth Diaper Sprayer--styles may vary\n",
       "1942                     Philips AVENT Newborn Starter Set\n",
       "20594    Motorola Digital Video Baby Monitor with Room ...\n",
       "10814               Ellaroo Mei Tai Baby Carrier - Hershey\n",
       "1810          Cosco Alpha Omega Elite Convertible Car Seat\n",
       "7310     Chicco Cortina KeyFit 30 Travel System in Adve...\n",
       "31226    Belkin WeMo Wi-Fi Baby Monitor for Apple iPhon...\n",
       "13751           Peg-Perego Tatamia High Chair, White Latte\n",
       "27231                     NUK Cook-n-Blend Baby Food Maker\n",
       "28120    VTech Communications Safe &amp; Sound Digital ...\n",
       "205                  Safety 1st Deluxe 4-in-1 Bath Station\n",
       "5831                Regalo My Cot Portable Bed, Royal Blue\n",
       "15062        Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.loc[ np.argsort(test_prob)[:20],'name' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Quiz Question**: Which of the following products are represented in the 20 most negative reviews?  [multiple choice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Compute accuracy of the classifier\n",
    "\n",
    "We will now evaluate the accuracy of the trained classifier. Recall that the accuracy is given by\n",
    "\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified examples}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "This can be computed as follows:\n",
    "\n",
    "* **Step 1:** Use the trained model to compute class predictions (**Hint:** Use the `predict` method)\n",
    "* **Step 2:** Count the number of data points when the predicted class labels match the ground truth labels (called `true_labels` below).\n",
    "* **Step 3:** Divide the total number of correct predictions by the total number of data points in the dataset.\n",
    "\n",
    "Complete the function below to compute the classification accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_classification_accuracy(model, data, true_labels):\n",
    "    # First get the predictions\n",
    "    ## YOUR CODE HERE\n",
    "    pred = model.predict(data)\n",
    "    \n",
    "    # Compute the number of correctly classified examples\n",
    "    ## YOUR CODE HERE\n",
    "    num_correct = sum( pred == true_labels)\n",
    "\n",
    "    # Then compute accuracy by dividing num_correct by total number of examples\n",
    "    ## YOUR CODE HERE\n",
    "    accuracy = num_correct/ len(true_labels)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute the classification accuracy of the **sentiment_model** on the **test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.93\n"
     ]
    }
   ],
   "source": [
    "acc = get_classification_accuracy(sentiment_model, test_matrix, test_data['sentiment'])\n",
    "print('Accuracy is ' + \"{:.2f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: What is the accuracy of the **sentiment_model** on the **test_data**? Round your answer to 2 decimal places (e.g. 0.76).\n",
    "\n",
    "**Quiz Question**: Does a higher accuracy value on the **training_data** always imply that the classifier is better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Learn another classifier with fewer words\n",
    "\n",
    "There were a lot of words in the model we trained above. We will now train a simpler logistic regression model using only a subset of words that occur in the reviews. For this assignment, we selected a 20 words to work with. These are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(significant_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a new set of word count vectors using only these words. The CountVectorizer class has a parameter that lets you limit the choice of words when building word count vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer_word_subset = CountVectorizer( vocabulary = significant_words) # limit to 20 words\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform( train_data['review_clean'] )\n",
    "test_matrix_word_subset  = vectorizer_word_subset.transform( test_data['review_clean'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Compute word count vectors for the training and test data and obtain the sparse matrices train_matrix_word_subset and test_matrix_word_subset, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Train a logistic regression model on a subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build a logistic regression classifier with **train_matrix_word_subset** as features and **sentiment** as the target. Call this model simple_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model = LogisticRegression()\n",
    "simple_model.fit( train_matrix_word_subset, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the classification accuracy using the `get_classification_accuracy` function you implemented earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86936045116390692"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(simple_model, test_matrix_word_subset , y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will inspect the weights (coefficients) of the **simple_model**:\n",
    "* First, build a table to store (word, coefficient) pairs. If you are using SFrame with scikit-learn, you can combine words with coefficients by running\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.36368976,  0.94399959,  1.19253827,  0.08551278,  0.52018576,\n",
       "         1.50981248,  1.67307389,  0.50376046,  0.19090857,  0.05885467,\n",
       "        -1.65157634, -0.20956286, -0.51137963, -2.03369861, -2.34829822,\n",
       "        -0.62116877, -0.32055624, -0.89803074, -0.36216674, -2.10933109]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sort the data frame by the coefficient value in descending order to obtain the coefficients with the most positive effect on the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loves           1.673074\n",
       "perfect         1.509812\n",
       "love            1.363690\n",
       "easy            1.192538\n",
       "great           0.944000\n",
       "little          0.520186\n",
       "well            0.503760\n",
       "able            0.190909\n",
       "old             0.085513\n",
       "car             0.058855\n",
       "less           -0.209563\n",
       "product        -0.320556\n",
       "would          -0.362167\n",
       "even           -0.511380\n",
       "work           -0.621169\n",
       "money          -0.898031\n",
       "broke          -1.651576\n",
       "waste          -2.033699\n",
       "return         -2.109331\n",
       "disappointed   -2.348298\n",
       "dtype: float64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = pd.Series(simple_model.coef_[0].tolist(), significant_words)\n",
    "coef.sort_values(ascending= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Consider the coefficients of **simple_model**. There should be 21 of them, an intercept term + one for each word in **significant_words**. How many of the 20 coefficients (corresponding to the 20 **significant_words** and *excluding the intercept term*) are positive for the `simple_model`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(coef > 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Are the positive words in the **simple_model** (let us call them `positive_significant_words`) also positive words in the **sentiment_model**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "perfect         1.865770\n",
       "love            1.582778\n",
       "loves           1.522427\n",
       "easy            1.361831\n",
       "great           1.233162\n",
       "little          0.640738\n",
       "well            0.542981\n",
       "able            0.391330\n",
       "car             0.123763\n",
       "old             0.054125\n",
       "product        -0.191745\n",
       "less           -0.276866\n",
       "would          -0.286739\n",
       "work           -0.463224\n",
       "even           -0.464966\n",
       "money          -0.786713\n",
       "broke          -1.396763\n",
       "return         -1.662928\n",
       "waste          -1.997541\n",
       "disappointed   -2.196958\n",
       "dtype: float64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get indice of significant_words in vectorizer :\n",
    "word_index = [vectorizer.vocabulary_[word]for word in significant_words] \n",
    "\n",
    "# find out the corresponding coef in sentiment_model\n",
    "sent_coef = pd.Series( sentiment_model.coef_[0][word_index], index = significant_words)\n",
    "sent_coef.sort_values( ascending= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Comparing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compare the accuracy of the **sentiment_model** and the **simple_model** using the `get_classification_accuracy` method you implemented above.\n",
    "\n",
    "First, compute the classification accuracy of the **sentiment_model** on the **train_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96848204113449665"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(sentiment_model, train_matrix , y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compute the classification accuracy of the **simple_model** on the **train_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8668225700065959"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(simple_model, train_matrix_word_subset , y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which model (**sentiment_model** or **simple_model**) has higher accuracy on the TRAINING set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will repeat this exercise on the **test_data**. Start by computing the classification accuracy of the **sentiment_model** on the **test_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93229541636669067"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(sentiment_model, test_matrix , y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will compute the classification accuracy of the **simple_model** on the **test_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86936045116390692"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(simple_model, test_matrix_word_subset , y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which model (**sentiment_model** or **simple_model**) has higher accuracy on the TEST set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Majority class prediction\n",
    "\n",
    "It is quite common to use the **majority class classifier** as the a baseline (or reference) model for comparison with your classifier model. The majority classifier model predicts the majority class for all data points. At the very least, you should healthily beat the majority class classifier, otherwise, the model is (usually) pointless.\n",
    "\n",
    "What is the majority class in the **train_data**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112164\n",
      "21252\n"
     ]
    }
   ],
   "source": [
    "num_positive  = (train_data['sentiment'] == +1).sum()\n",
    "num_negative = (train_data['sentiment'] == -1).sum()\n",
    "print num_positive\n",
    "print num_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the accuracy of the majority class classifier on **test_data**.\n",
    "\n",
    "**Quiz Question**: Enter the accuracy of the majority class classifier model on the **test_data**. Round your answer to two decimal places (e.g. 0.76)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84\n"
     ]
    }
   ],
   "source": [
    "print(\"{:.2f}\".format(sum(y_test==1 )/len(y_test)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Is the **sentiment_model** definitely better than the majority class classifier (the baseline)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
