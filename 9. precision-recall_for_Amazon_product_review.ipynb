{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring precision and recall\n",
    "\n",
    "The goal of this second notebook is to understand precision-recall in the context of classifiers.\n",
    "\n",
    " * Use Amazon review data in its entirety.\n",
    " * Train a logistic regression model.\n",
    " * Explore various evaluation metrics: accuracy, confusion matrix, precision, recall.\n",
    " * Explore how various metrics can be combined to produce a cost of making an error.\n",
    " * Explore precision and recall curves.\n",
    " \n",
    "Because we are using the full Amazon review dataset (not a subset of words or reviews), in this assignment we return to using GraphLab Create for its efficiency. As usual, let's start by **firing up GraphLab Create**.\n",
    "\n",
    "Make sure you have the latest version of GraphLab Create (1.8.3 or later). If you don't find the decision tree module, then you would need to upgrade graphlab-create using\n",
    "\n",
    "```\n",
    "   pip install graphlab-create --upgrade\n",
    "```\n",
    "See [this page](https://dato.com/download/) for detailed instructions on upgrading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "%matplotlib inline\n",
    "#graphlab.canvas.set_target('ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load amazon review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/Users/qiaolinchen/Documents/Courses/UW-classification/data/'\n",
    "products = pd.read_csv(data_path +'amazon_baby.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183531, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  \\\n",
       "0  Planetwise Flannel Wipes   \n",
       "1     Planetwise Wipe Pouch   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(products.shape)\n",
    "products.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Perform text cleaning\n",
    "\n",
    "## 2.1 Extract word counts and sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the first assignment of this course, we compute the word counts for individual words and extract positive and negative sentiments from ratings. To summarize, we perform the following:\n",
    "\n",
    "1. Remove punctuation.\n",
    "2. Remove reviews with \"neutral\" sentiment (rating 3).\n",
    "3. Set reviews with rating 4 or more to be positive and those with 2 or less to be negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    try:\n",
    "        return text.translate(None, string.punctuation) \n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "products = products.fillna({'review':''})  # fill in N/A's in the review column\n",
    "products = products.fillna({'name':''})  # fill in N/A's in the review column\n",
    "\n",
    "\n",
    "\n",
    "# Remove punctuation.\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)\n",
    "products = products.fillna({'review_clean':''})  # fill in N/A's in the review column\n",
    "\n",
    "# Drop neutral sentiment reviews.\n",
    "products = products[products['rating'] != 3]\n",
    "\n",
    "# Positive sentiment to +1 and negative sentiment to -1\n",
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's remember what the dataset looks like by taking a quick peek:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Split data into training and test sets\n",
    "\n",
    "We split the data into a 80-20 split where 80% is in the training set and 20% is in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products.reset_index().drop('index', axis=1)\n",
    "#train_data, test_data = products.random_split(.8, seed=1)\n",
    "train_indices = pd.read_json(data_path + 'module-9-assignment-train-idx.json')[0].tolist()\n",
    "test_indices  = pd.read_json(data_path + 'module-9-assignment-test-idx.json')[0].tolist()\n",
    "\n",
    "train_data = products.loc[train_indices]\n",
    "test_data = products.loc[test_indices]\n",
    "\n",
    "train_data = train_data.reset_index()\n",
    "test_data =  test_data.reset_index()\n",
    "\n",
    "train_data = train_data.drop(['index' ], axis= 1  )\n",
    "test_data  = test_data.drop (['index' ], axis= 1  )\n",
    "\n",
    "y_train = train_data['sentiment']\n",
    "y_test  = test_data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  \\\n",
       "0                Planetwise Wipe Pouch   \n",
       "1  Annas Dream Full Quilt with 2 Shams   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  it came early and was not disappointed. i love...       5   \n",
       "1  Very soft and comfortable and warmer than it l...       5   \n",
       "\n",
       "                                        review_clean  sentiment  \n",
       "0  it came early and was not disappointed i love ...          1  \n",
       "1  Very soft and comfortable and warmer than it l...          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>This has been an easy way for my nanny to reco...</td>\n",
       "      <td>4</td>\n",
       "      <td>This has been an easy way for my nanny to reco...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>I love this journal and our nanny uses it ever...</td>\n",
       "      <td>4</td>\n",
       "      <td>I love this journal and our nanny uses it ever...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "1  Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  This has been an easy way for my nanny to reco...       4   \n",
       "1  I love this journal and our nanny uses it ever...       4   \n",
       "\n",
       "                                        review_clean  sentiment  \n",
       "0  This has been an easy way for my nanny to reco...          1  \n",
       "1  I love this journal and our nanny uses it ever...          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Build the word count vector for each review\n",
    "\n",
    "We will now compute the word count for each word that appears in the reviews. \n",
    "* A vector consisting of word counts is often referred to as **bag-of-word features**. \n",
    "* Since most words occur in only a few reviews, word count vectors are sparse. \n",
    "For this reason, scikit-learn and many other tools use sparse matrices to store a collection of word count vectors. Refer to appropriate manuals to produce sparse word count vectors. \n",
    "\n",
    "General steps for extracting word count vectors are as follows:\n",
    "1. Learn a vocabulary (set of all words) from the training data. Only the words that show up in the training data will be considered for feature extraction.\n",
    "2. Compute the occurrences of the words in each review and collect them into a row vector.\n",
    "3. Build a sparse matrix where each row is the word count vector for the corresponding review. Call this matrix train_matrix.\n",
    "4. Using the same mapping between words and columns, convert the test data into a sparse matrix test_matrix.\n",
    "\n",
    "The following cell uses CountVectorizer in scikit-learn. Notice the **token_pattern** argument in the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "     # Use this token pattern to keep single-letter words\n",
    "# First, learn vocabulary from the training data and assign columns to words\n",
    "# Then convert the training data into a sparse matrix\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train a logistic regression classifier\n",
    "\n",
    "We will now train a logistic regression classifier with **sentiment** as the target and **word_count** as the features. We will set `validation_set=None` to make sure everyone gets exactly the same results.  \n",
    "\n",
    "Remember, even though we now know how to implement logistic regression, we will use GraphLab Create for its efficiency at processing this Amazon dataset in its entirety.  The focus of this assignment is instead on the topic of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf= LogisticRegression()\n",
    "model = clf.fit(train_matrix , y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore the advanced model evaluation concepts that were discussed in the lectures.\n",
    "\n",
    "## Accuracy\n",
    "\n",
    "One performance metric we will use for our more advanced exploration is accuracy, which we have seen many times in past assignments.  Recall that the accuracy is given by\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified data points}}{\\mbox{# total data points}}\n",
    "$$\n",
    "\n",
    "To obtain the accuracy of our trained models using GraphLab Create, simply pass the option `metric='accuracy'` to the `evaluate` function. We compute the **accuracy** of our logistic regression model on the **test_data** as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.932295416367\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy= accuracy_score(y_test, model.predict(test_matrix))\n",
    "print \"Test Accuracy: %s\" % accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Majority class prediction\n",
    "\n",
    "Recall from an earlier assignment that we used the **majority class classifier** as a baseline (i.e reference) model for a point of comparison with a more sophisticated classifier. The majority classifier model predicts the majority class for all data points. \n",
    "\n",
    "Typically, a good model should beat the majority class classifier. Since the majority class in this dataset is the positive class (i.e., there are more positive than negative reviews), the accuracy of the majority class classifier can be computed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy (majority class classifier): 0.842782577394\n"
     ]
    }
   ],
   "source": [
    "baseline = len(test_data[test_data['sentiment'] == 1])/len(test_data)\n",
    "print \"Baseline accuracy (majority class classifier): %s\" % baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quiz Question:** Using accuracy as the evaluation metric, was our **logistic regression model** better than the baseline (majority class classifier)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "The accuracy, while convenient, does not tell the whole story. For a fuller picture, we turn to the **confusion matrix**. In the case of binary classification, the confusion matrix is a 2-by-2 matrix laying out correct and incorrect predictions made in each label as follows:\n",
    "```\n",
    "              +---------------------------------------------+\n",
    "              |                Predicted label              |\n",
    "              +----------------------+----------------------+\n",
    "              |          (-1)        |         (+1)         |\n",
    "+-------+-----+----------------------+----------------------+\n",
    "| True  |(-1) | # of true negatives  | # of false positives |\n",
    "| label +-----+----------------------+----------------------+\n",
    "|       |(+1) | # of false negatives | # of true positives  |\n",
    "+-------+-----+----------------------+----------------------+\n",
    "```\n",
    "To print out the confusion matrix for a classifier, use `metric='confusion_matrix'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3788  1453]\n",
      " [  804 27291]]\n"
     ]
    }
   ],
   "source": [
    "confusion_mat = confusion_matrix(y_test, model.predict(test_matrix))\n",
    "#  TN FP  \n",
    "#  FN TP\n",
    "print(confusion_mat)\n",
    "TN = confusion_mat[0,0]\n",
    "FP = confusion_mat[0,1]\n",
    "FN = confusion_mat[1,0]\n",
    "TP = confusion_mat[1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: How many predicted values in the **test set** are **false positives**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1453"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the cost of mistakes\n",
    "\n",
    "\n",
    "Put yourself in the shoes of a manufacturer that sells a baby product on Amazon.com and you want to monitor your product's reviews in order to respond to complaints.  Even a few negative reviews may generate a lot of bad publicity about the product. So you don't want to miss any reviews with negative sentiments --- you'd rather put up with false alarms about potentially negative reviews instead of missing negative reviews entirely. In other words, **false positives cost more than false negatives**. (It may be the other way around for other scenarios, but let's stick with the manufacturer's scenario for now.)\n",
    "\n",
    "Suppose you know the costs involved in each kind of mistake: \n",
    "1. \\$100 for each false positive.\n",
    "2. \\$1 for each false negative.\n",
    "3. Correctly classified reviews incur no cost.\n",
    "\n",
    "**Quiz Question**: Given the stipulation, what is the cost associated with the logistic regression classifier's performance on the **test set**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146104"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP* 100 + FN*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may not have exact dollar amounts for each kind of mistake. Instead, you may simply prefer to reduce the percentage of false positives to be less than, say, 3.5% of all positive predictions. This is where **precision** comes in:\n",
    "\n",
    "$$\n",
    "[\\text{precision}] = \\frac{[\\text{# positive data points with positive predicitions}]}{\\text{[# all data points with positive predictions]}} = \\frac{[\\text{# true positives}]}{[\\text{# true positives}] + [\\text{# false positives}]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to keep the percentage of false positives below 3.5% of positive predictions, we must raise the precision to 96.5% or higher. \n",
    "\n",
    "**First**, let us compute the precision of the logistic regression classifier on the **test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on test data: 0.95\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, model.predict(test_matrix))\n",
    "print \"Precision on test data:\", \"{:.2f}\".format(precision)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Out of all reviews in the **test set** that are predicted to be positive, what fraction of them are **false positives**? (Round to the second decimal place e.g. 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n"
     ]
    }
   ],
   "source": [
    "print( \"{:.2f}\".format(1.0* FP/(TP+FP)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** Based on what we learned in lecture, if we wanted to reduce this fraction of false positives to be below 3.5%, we would: (see the quiz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A complementary metric is **recall**, which measures the ratio between the number of true positives and that of (ground-truth) positive reviews:\n",
    "\n",
    "$$\n",
    "[\\text{recall}] = \\frac{[\\text{# positive data points with positive predicitions}]}{\\text{[# all positive data points]}} = \\frac{[\\text{# true positives}]}{[\\text{# true positives}] + [\\text{# false negatives}]}\n",
    "$$\n",
    "\n",
    "Let us compute the recall on the **test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall on test data: %s 0.97\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_test, model.predict(test_matrix))\n",
    "print \"Recall on test data: %s\", \"{:.2f}\".format(recall)  \n",
    "print( \"{:.2f}\".format(1.0* TP/(TP+FN)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: What fraction of the positive reviews in the **test_set** were correctly predicted as positive by the classifier?\n",
    "\n",
    "**Quiz Question**: What is the recall value for a classifier that predicts **+1** for all data points in the **test_data**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Precision-recall tradeoff\n",
    "\n",
    "In this part, we will explore the trade-off between precision and recall discussed in the lecture.  We first examine what happens when we use a different threshold value for making class predictions.  We then explore a range of threshold values and plot the associated precision-recall curve.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying the threshold\n",
    "\n",
    "False positives are costly in our example, so we may want to be more conservative about making positive predictions. To achieve this, instead of thresholding class probabilities at 0.5, we can choose a higher threshold. \n",
    "\n",
    "Write a function called `apply_threshold` that accepts two things\n",
    "* `probabilities` (an SArray of probability values)\n",
    "* `threshold` (a float between 0 and 1).\n",
    "\n",
    "The function should return an SArray, where each element is set to +1 or -1 depending whether the corresponding probability exceeds `threshold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_threshold(probabilities, threshold):\n",
    "    # +1 if >= threshold and -1 otherwise.\n",
    "    pred = [ +1 if p>= threshold else -1 for p in probabilities]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run prediction with `output_type='probability'` to get the list of probability values. Then use thresholds set at 0.5 (default) and 0.9 to make predictions from these probability values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probabilities = model.predict_proba(test_matrix)[:,1]\n",
    "predictions_with_default_threshold = apply_threshold(probabilities, 0.5)\n",
    "predictions_with_high_threshold = apply_threshold(probabilities, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive predicted reviews (threshold = 0.5): 28744\n"
     ]
    }
   ],
   "source": [
    "pred_pos = sum(map(lambda x: int(x==1), predictions_with_default_threshold ))\n",
    "print \"Number of positive predicted reviews (threshold = 0.5): %s\" % pred_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive predicted reviews (threshold = 0.9): 25071\n"
     ]
    }
   ],
   "source": [
    "pred_pos2 = sum(map(lambda x: int(x==1), predictions_with_high_threshold ))\n",
    "print \"Number of positive predicted reviews (threshold = 0.9): %s\" % pred_pos2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: What happens to the number of positive predicted reviews as the threshold increased from 0.5 to 0.9?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the associated precision and recall as the threshold varies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By changing the probability threshold, it is possible to influence precision and recall. We can explore this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Threshold = 0.5\n",
    "precision_with_default_threshold = precision_score(test_data['sentiment'],\n",
    "                                        predictions_with_default_threshold)\n",
    "\n",
    "recall_with_default_threshold = recall_score(test_data['sentiment'],\n",
    "                                        predictions_with_default_threshold)\n",
    "\n",
    "# Threshold = 0.9\n",
    "precision_with_high_threshold = precision_score(test_data['sentiment'],\n",
    "                                        predictions_with_high_threshold)\n",
    "recall_with_high_threshold = recall_score(test_data['sentiment'],\n",
    "                                        predictions_with_high_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (threshold = 0.5): 0.949450320067\n",
      "Recall (threshold = 0.5)   : 0.971382808329\n"
     ]
    }
   ],
   "source": [
    "print \"Precision (threshold = 0.5): %s\" % precision_with_default_threshold\n",
    "print \"Recall (threshold = 0.5)   : %s\" % recall_with_default_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (threshold = 0.9): 0.981492561126\n",
      "Recall (threshold = 0.9)   : 0.875849795337\n"
     ]
    }
   ],
   "source": [
    "print \"Precision (threshold = 0.9): %s\" % precision_with_high_threshold\n",
    "print \"Recall (threshold = 0.9)   : %s\" % recall_with_high_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question (variant 1)**: Does the **precision** increase with a higher threshold?\n",
    "\n",
    "**Quiz Question (variant 2)**: Does the **recall** increase with a higher threshold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-recall curve\n",
    "\n",
    "Now, we will explore various different values of tresholds, compute the precision and recall scores, and then plot the precision-recall curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5         0.50505051  0.51010101  0.51515152  0.52020202  0.52525253\n",
      "  0.53030303  0.53535354  0.54040404  0.54545455  0.55050505  0.55555556\n",
      "  0.56060606  0.56565657  0.57070707  0.57575758  0.58080808  0.58585859\n",
      "  0.59090909  0.5959596   0.6010101   0.60606061  0.61111111  0.61616162\n",
      "  0.62121212  0.62626263  0.63131313  0.63636364  0.64141414  0.64646465\n",
      "  0.65151515  0.65656566  0.66161616  0.66666667  0.67171717  0.67676768\n",
      "  0.68181818  0.68686869  0.69191919  0.6969697   0.7020202   0.70707071\n",
      "  0.71212121  0.71717172  0.72222222  0.72727273  0.73232323  0.73737374\n",
      "  0.74242424  0.74747475  0.75252525  0.75757576  0.76262626  0.76767677\n",
      "  0.77272727  0.77777778  0.78282828  0.78787879  0.79292929  0.7979798\n",
      "  0.8030303   0.80808081  0.81313131  0.81818182  0.82323232  0.82828283\n",
      "  0.83333333  0.83838384  0.84343434  0.84848485  0.85353535  0.85858586\n",
      "  0.86363636  0.86868687  0.87373737  0.87878788  0.88383838  0.88888889\n",
      "  0.89393939  0.8989899   0.9040404   0.90909091  0.91414141  0.91919192\n",
      "  0.92424242  0.92929293  0.93434343  0.93939394  0.94444444  0.94949495\n",
      "  0.95454545  0.95959596  0.96464646  0.96969697  0.97474747  0.97979798\n",
      "  0.98484848  0.98989899  0.99494949  1.        ]\n"
     ]
    }
   ],
   "source": [
    "threshold_values = np.linspace(0.5, 1, num=100)\n",
    "print threshold_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the values of threshold, we compute the precision and recall scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_all = []\n",
    "recall_all = []\n",
    "\n",
    "probabilities = model.predict_proba(test_matrix)[:,1]\n",
    "for threshold in threshold_values:\n",
    "    predictions = apply_threshold(probabilities, threshold)\n",
    "    \n",
    "    precision = precision_score(test_data['sentiment'], predictions)\n",
    "    recall    = recall_score(test_data['sentiment'], predictions)\n",
    "    \n",
    "    precision_all.append(precision)\n",
    "    recall_all.append(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the precision-recall curve to visualize the precision-recall tradeoff as we vary the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAFNCAYAAACUvLFdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNRR6IiKSNf4/GqJfWkC2nEMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10aa4a890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_pr_curve(precision, recall, title):\n",
    "    plt.rcParams['figure.figsize'] = 7, 5\n",
    "    plt.locator_params(axis = 'x', nbins = 5)\n",
    "    plt.plot(precision, recall, 'b-', linewidth=4.0, color = '#B0017F')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Precision')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    \n",
    "plot_pr_curve(precision_all, recall_all, 'Precision recall curve (all)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.949450</td>\n",
       "      <td>0.971383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.949955</td>\n",
       "      <td>0.970884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.510101</td>\n",
       "      <td>0.950396</td>\n",
       "      <td>0.970422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.951005</td>\n",
       "      <td>0.969995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.951388</td>\n",
       "      <td>0.969674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold  Precision    Recall\n",
       "0   0.500000   0.949450  0.971383\n",
       "1   0.505051   0.949955  0.970884\n",
       "2   0.510101   0.950396  0.970422\n",
       "3   0.515152   0.951005  0.969995\n",
       "4   0.520202   0.951388  0.969674"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall = pd.concat([pd.Series(threshold_values), pd.Series(precision_all) , pd.Series(recall_all)], axis=1)\n",
    "precision_recall.columns = ['Threshold', 'Precision', 'Recall']\n",
    "precision_recall.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Among all the threshold values tried, what is the **smallest** threshold value that achieves a precision of 96.5% or better? Round your answer to 3 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.965152</td>\n",
       "      <td>0.949315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold  Precision    Recall\n",
       "41   0.707071   0.965152  0.949315"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall.loc[ precision_recall['Precision']>= 0.965,].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Using `threshold` = 0.98, how many **false negatives** do we get on the **test_data**? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5047,   194],\n",
       "       [ 8211, 19884]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = model.predict_proba(test_matrix)[:,1]\n",
    "pred = [+1 if p >= 0.98 else -1 for p in probabilities]\n",
    "confusion_matrix(y_test, pred)\n",
    "#  TN FP  \n",
    "#  FN TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the number of false negatives (i.e the number of reviews to look at when not needed) that we have to deal with using this classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating specific search terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we looked at the number of false positives for the **entire test set**. In this section, let's select reviews using a specific search term and optimize the precision on these reviews only. After all, a manufacturer would be interested in tuning the false positive rate just for their products (the reviews they want to read) rather than that of the entire set of products on Amazon.\n",
    "\n",
    "## Precision-Recall on all baby related items\n",
    "\n",
    "From the **test set**, select all the reviews for all products with the word 'baby' in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>This has been an easy way for my nanny to reco...</td>\n",
       "      <td>4</td>\n",
       "      <td>This has been an easy way for my nanny to reco...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>I love this journal and our nanny uses it ever...</td>\n",
       "      <td>4</td>\n",
       "      <td>I love this journal and our nanny uses it ever...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baby's First Year Undated Wall Calendar with S...</td>\n",
       "      <td>I searched high and low for a first year calen...</td>\n",
       "      <td>5</td>\n",
       "      <td>I searched high and low for a first year calen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>Absolutely love it and all of the Scripture in...</td>\n",
       "      <td>5</td>\n",
       "      <td>Absolutely love it and all of the Scripture in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Newborn Baby Tracker&amp;reg; - Round the Clock Ch...</td>\n",
       "      <td>This is the best way to keep track of when you...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is the best way to keep track of when you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  \\\n",
       "0   Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "1   Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "9   Baby's First Year Undated Wall Calendar with S...   \n",
       "10                          Our Baby Girl Memory Book   \n",
       "13  Newborn Baby Tracker&reg; - Round the Clock Ch...   \n",
       "\n",
       "                                               review  rating  \\\n",
       "0   This has been an easy way for my nanny to reco...       4   \n",
       "1   I love this journal and our nanny uses it ever...       4   \n",
       "9   I searched high and low for a first year calen...       5   \n",
       "10  Absolutely love it and all of the Scripture in...       5   \n",
       "13  This is the best way to keep track of when you...       5   \n",
       "\n",
       "                                         review_clean  sentiment  \n",
       "0   This has been an easy way for my nanny to reco...          1  \n",
       "1   I love this journal and our nanny uses it ever...          1  \n",
       "9   I searched high and low for a first year calen...          1  \n",
       "10  Absolutely love it and all of the Scripture in...          1  \n",
       "13  This is the best way to keep track of when you...          1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baby_reviews =  test_data[test_data['name'].apply(lambda x: 'baby' in x.lower())]\n",
    "baby_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For test data, we use vectorizer.transform() instead of fit_transform(), to perform the same transform as training data\n",
    "baby_matrix = vectorizer.transform(baby_reviews['review_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's predict the probability of classifying these reviews as positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7843666 ,  0.99999924,  0.99736899, ...,  0.93008186,\n",
       "        0.99999999,  0.98176042])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = model.predict_proba(baby_matrix)[:,1]\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the precision-recall curve for the **baby_reviews** dataset.\n",
    "\n",
    "**First**, let's consider the following `threshold_values` ranging from 0.5 to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold_values = np.linspace(0.5, 1, num=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second**, as we did above, let's compute precision and recall for each value in `threshold_values` on the **baby_reviews** dataset.  Complete the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision_all = []\n",
    "recall_all = []\n",
    "y_true = baby_reviews['sentiment']\n",
    "for threshold in threshold_values:\n",
    "    \n",
    "    # Make predictions. Use the `apply_threshold` function \n",
    "    predictions = [+1 if p >= threshold else -1 for p in probabilities]\n",
    "\n",
    "    # Calculate the precision.\n",
    "    precision = precision_score(y_true, predictions)\n",
    "    recall = recall_score(y_true, predictions)\n",
    "    \n",
    "    # Append the precision and recall scores.\n",
    "    precision_all.append(precision)\n",
    "    recall_all.append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.946657</td>\n",
       "      <td>0.967824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.947144</td>\n",
       "      <td>0.967460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.510101</td>\n",
       "      <td>0.947603</td>\n",
       "      <td>0.966552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.948420</td>\n",
       "      <td>0.966006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.948919</td>\n",
       "      <td>0.965824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold  Precision    Recall\n",
       "0   0.500000   0.946657  0.967824\n",
       "1   0.505051   0.947144  0.967460\n",
       "2   0.510101   0.947603  0.966552\n",
       "3   0.515152   0.948420  0.966006\n",
       "4   0.520202   0.948919  0.965824"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall = pd.concat([pd.Series(threshold_values), pd.Series(precision_all) , pd.Series(recall_all)], axis=1)\n",
    "precision_recall.columns = ['Threshold', 'Precision', 'Recall']\n",
    "precision_recall.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Among all the threshold values tried, what is the **smallest** threshold value that achieves a precision of 96.5% or better for the reviews of data in **baby_reviews**? Round your answer to 3 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.732323</td>\n",
       "      <td>0.965079</td>\n",
       "      <td>0.939466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold  Precision    Recall\n",
       "46   0.732323   0.965079  0.939466"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall.loc[ precision_recall['Precision']>= 0.965,].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** Is this threshold value smaller or larger than the threshold used for the entire dataset to achieve the same specified precision of 96.5%?\n",
    "\n",
    "**Finally**, let's plot the precision recall curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFcCAYAAABFvY7FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKGGKiIgkQQlTREQkCUqYIiIiSfh/Ptaxhn/9mRIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114c25b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pr_curve(precision_all, recall_all, \"Precision-Recall (Baby)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
